{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "mypath = \"C:/Users/sunyu666/Desktop/cirGAN/data/my308470\"\n",
    "from model import Generator\n",
    "from model import Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pics(pics,heatmap = np.zeros((1,1))):\n",
    "    plt.figure(figsize=(3*len(pics),3),dpi=80)\n",
    "    for i in range(len(pics)):\n",
    "        pics[i] = (pics[i][0].transpose((1,2,0))+1) / 2\n",
    "        plt.subplot(1,len(pics),i+1)\n",
    "        print(pics[i])\n",
    "        plt.imshow(pics[i])\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_1 = [\n",
    "    transforms.Resize(int(256 * 1.12)),   ## 图片放大1.12倍\n",
    "    transforms.RandomCrop((256, 256)),         ## 随机裁剪成原来的大小\n",
    "    transforms.RandomHorizontalFlip(),                              ## 随机水平翻转\n",
    "    transforms.ToTensor(),                                          ## 变为Tensor数据\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),         ## 正则化\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG():\n",
    "    def __init__(self):\n",
    "        self.data_dir='./data/my308470/'\n",
    "        self.shuffle = True\n",
    "        self.dataset = mypath\n",
    "        self.model_net = 'CycleGAN'\n",
    "        self.train_list = None\n",
    "        self.batch_size = 1\n",
    "        self.drop_last = False\n",
    "        self.run_test = True\n",
    "        self.crop_size = 224\n",
    "        self.load_size = 256\n",
    "        self.crop_type = 'Random'\n",
    "        self.phase = 'train'\n",
    "        self.list_filename = None\n",
    "        self.use_gpu = True\n",
    "        self.return_name = False\n",
    "\n",
    "\n",
    "\n",
    "class reader_creator(Dataset):\n",
    "    def __init__(self,this_cfg,transforms_ = None):\n",
    "        super(Dataset,self).__init__()\n",
    "        self.image_dir =  this_cfg.image_dir\n",
    "        self.shuffle = this_cfg.shuffle\n",
    "        self.dataset = this_cfg.dataset\n",
    "        self.model_net = this_cfg.model_net\n",
    "        self.list_filename = this_cfg.list_filename\n",
    "        self.batch_size = this_cfg.batch_size\n",
    "        self.drop_last = this_cfg.drop_last\n",
    "        self.run_test = this_cfg.run_test\n",
    "        self.load_size = this_cfg.load_size\n",
    "        self.crop_type = this_cfg.crop_type\n",
    "        self.crop_size = this_cfg.crop_size\n",
    "        self.phase = this_cfg.phase\n",
    "        self.return_name = this_cfg.return_name\n",
    "        self.lines = open(self.list_filename).readlines()\n",
    "        self.cfg = this_cfg\n",
    "        self.transform = transforms.Compose(transforms_) \n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.lines)\n",
    "\n",
    "    def len(self):\n",
    "        if self.drop_last or len(self.lines) % self.batch_size == 0:\n",
    "            return len(self.lines) // self.batch_size\n",
    "        else:\n",
    "            return len(self.lines) // self.batch_size + 1\n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file = self.lines[index]\n",
    "        file = file.strip('\\n\\t\\r')\n",
    "        img  = Image.open(os.path.join(self.image_dir,file)).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "\n",
    "class dataloader(Dataset):\n",
    "    def __init__(self,cfg):\n",
    "        super(Dataset,self).__init__()\n",
    "        self.cfg = cfg\n",
    "        self.shuffle = self.cfg.shuffle\n",
    "    def make_data(self):\n",
    "        data_dir = os.path.join(self.cfg.data_dir)\n",
    "        trainA_list = os.path.join(data_dir,'trainA.txt')\n",
    "        trainB_list = os.path.join(data_dir,'trainB.txt')\n",
    "        self.cfg.image_dir = data_dir\n",
    "        self.cfg.list_filename = trainA_list\n",
    "        self.cfg.phase = 'train'\n",
    "        a_train_reader = reader_creator(self.cfg,transforms_1)\n",
    "        self.cfg.list_filename = trainB_list\n",
    "        b_train_reader = reader_creator(self.cfg,transforms_1)\n",
    "        a_test_reader = None\n",
    "        b_test_reader = None\n",
    "        batch_num = max(a_train_reader.len(),b_train_reader.len())\n",
    "        return a_train_reader,b_train_reader,a_test_reader,b_test_reader,batch_num\n",
    "\n",
    "#cfg = CFG()\n",
    "\n",
    "#reader = dataloader(cfg)\n",
    "#a_reader,b_reader,a_test,b_test,batch_num = reader.make_data()\n",
    "\n",
    "#A_reader = DataLoader(a_reader,shuffle=True,drop_last=cfg.drop_last,batch_size=cfg.batch_size,num_workers=0)\n",
    "#B_reader = DataLoader(b_reader,shuffle=True,drop_last=cfg.drop_last,batch_size=cfg.batch_size,num_workers=0)\n",
    "\n",
    "\n",
    "#data_A = A_reader\n",
    "'''\n",
    "print(len(data_A))\n",
    "for  data in zip(data_A):\n",
    "    print(data.shape[0],data.shape[1],data.shape[2],data.shape[3])\n",
    "    print(len(data))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_pic(pics,file_name = 'temp',save_path = './output/pics/'):\n",
    "    for i in range(len(pics)):\n",
    "        pics[i] = pics[i][0]\n",
    "    pic = np.concatenate(tuple(pics),axis=2)\n",
    "    pic = pic.transpose((1,2,0))\n",
    "    pic = np.clip(pic*256,0,255)\n",
    "    img = Image.fromarray(pic.astype('uint8')).convert('RGB')\n",
    "    img.save(save_path+file_name+'.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from PIL import Image, ImageEnhance\n",
    "class ImagePool(object):\n",
    "    def __init__(self,pool_size = 50):\n",
    "        self.pool = []\n",
    "        self.count = 0\n",
    "        self.pool_size = pool_size\n",
    "    def pool_image(self,image):\n",
    "        rnt = image\n",
    "        if self.count < self.pool_size:\n",
    "            self.pool.append(image)\n",
    "            self.count += 1\n",
    "            rnt = image\n",
    "        else:\n",
    "            p = np.random.rand()\n",
    "            print(p)\n",
    "            if p > 0.5:\n",
    "                random_id = np.random.randint(0,self.pool_size-1)\n",
    "                temp = self.pool[random_id]\n",
    "                #print(temp)\n",
    "                self.pool[random_id] = image\n",
    "                rtn = temp\n",
    "            else:\n",
    "                rtn = image\n",
    "                #print(rnt)\n",
    "        return (rnt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _save_model(self,epoch):\n",
    "    print('save model epoch %d'%epoch)\n",
    "    torch.save\n",
    "def trian(epoch_num = 1000,\n",
    "            adv_weight = 1,\n",
    "        cycle_weight = 30,\n",
    "        identity_weight = 10,\n",
    "        use_gpu = True,\n",
    "        load_model = False,\n",
    "        model_path = './model/',\n",
    "        model_path_bkp = './model_bkp/',\n",
    "        print_interval = 1,\n",
    "        max_step = 50,\n",
    "        model_bkp_intercval = 5000):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(device)\n",
    "    \n",
    "    g_x = Generator().to(device)\n",
    "    g_y = Generator().to(device)\n",
    "\n",
    "    #此处创建两个判别器\n",
    "    d_x = Discriminator().to(device)\n",
    "    d_y = Discriminator().to(device)\n",
    "\n",
    "    cfg = CFG()\n",
    "    loader = dataloader(cfg)\n",
    "    a_reader,b_reader,a_test_reader,b_test_reader,batch_num = loader.make_data()\n",
    "    \n",
    "    x_train_data = DataLoader(a_reader,shuffle=True,drop_last=cfg.drop_last,batch_size=cfg.batch_size,num_workers=0)\n",
    "    y_train_data = DataLoader(b_reader,shuffle=True,drop_last=cfg.drop_last,batch_size=cfg.batch_size,num_workers=0)\n",
    "\n",
    "    \n",
    "\n",
    "    g_x_optimizer = torch.optim.Adam(g_x.parameters(),lr= 0.0001,betas=(0.5,0.999))\n",
    "    g_y_optimizer = torch.optim.Adam(g_y.parameters(),lr= 0.0001,betas=(0.5,0.999))\n",
    "\n",
    "    d_x_optimizer = torch.optim.Adam(d_x.parameters(),lr= 0.0001,betas=(0.5,0.999))\n",
    "    d_y_optimizer = torch.optim.Adam(d_y.parameters(),lr= 0.0001,betas=(0.5,0.999))\n",
    "\n",
    "    fb_pool = ImagePool()\n",
    "    fa_pool = ImagePool()\n",
    "    \n",
    "    #if load_model == True:#load_model\n",
    "    steps = 0\n",
    "    \n",
    "    for epoch in range(100):\n",
    "        print(\"----epoches%d -------\"%(epoch))\n",
    "        for data_x,data_y in zip(x_train_data,y_train_data):\n",
    "            steps += 1\n",
    "            #print(len(data_x))\n",
    "            #print(len(data_y))\n",
    "            print(steps)\n",
    "            image_rx = data_x[0].reshape(1,3,256,256).to(device)\n",
    "            image_ry = data_y[0].reshape(1,3,256,256).to(device)\n",
    "            \n",
    "            #print(type(image_rx))\n",
    "            #print(image_rx.shape)\n",
    "\n",
    "\n",
    "            gx_gan_loss = torch.mean((d_x(g_x(image_ry.detach()))-1)**2)\n",
    "            gx_cycle_loss = torch.mean(torch.abs(image_ry.detach() - g_y(g_x(image_ry.detach()))))\n",
    "            gx_ide_loss = torch.mean(torch.abs(image_rx.detach() - (g_x(image_rx.detach()))))\n",
    "            gx_loss = adv_weight * gx_gan_loss + cycle_weight * gx_cycle_loss + identity_weight * gx_ide_loss\n",
    "            g_x_optimizer.zero_grad()\n",
    "            gx_loss.backward()\n",
    "            g_x_optimizer.step()\n",
    "            #训练生成器1\n",
    "\n",
    "            #print(gx_loss)\n",
    "\n",
    "            gy_gan_loss = torch.mean((d_y(g_y(image_rx.detach()))-1)**2)\n",
    "            gy_cycle_loss = torch.mean(torch.abs(image_rx.detach() - g_x(g_y(image_rx.detach()))))\n",
    "            gy_ide_loss = torch.mean(torch.abs(image_ry.detach() - (g_y(image_ry.detach()))))\n",
    "            gy_loss = adv_weight * gy_gan_loss + cycle_weight * gy_cycle_loss + identity_weight * gy_ide_loss\n",
    "            g_y_optimizer.zero_grad()\n",
    "            gy_loss.backward()\n",
    "            g_y_optimizer.step()\n",
    "            #训练生成器2\n",
    "            #print(gy_loss)\n",
    "            #print(\"------------------\")\n",
    "\n",
    "            d_loss_rx = torch.mean((d_x(image_rx.detach())-1)**2) \n",
    "            #print(d_loss_ra)\n",
    "            d_loss_fx = torch.mean(d_x(fa_pool.pool_image(g_x(image_ry.detach())))**2)\n",
    "            #print(d_loss_fa)\n",
    "            d_x_loss = (d_loss_fx + d_loss_rx) * 0.5\n",
    "            d_x_optimizer.zero_grad()\n",
    "            d_x_loss.backward()\n",
    "            d_x_optimizer.step()\n",
    "            #print(d_x_loss)\n",
    "            #训练判别器1\n",
    "\n",
    "\n",
    "            d_loss_ry = torch.mean((d_y(image_ry.detach())-1)**2) \n",
    "            d_loss_fy = torch.mean(d_y(fb_pool.pool_image(g_y(image_rx.detach())))**2)\n",
    "            d_y_loss = (d_loss_fy + d_loss_ry) * 0.5\n",
    "            d_y_optimizer.zero_grad()\n",
    "            d_y_loss.backward()\n",
    "            d_y_optimizer.step()\n",
    "            #训练判别器2\n",
    "            #print(d_y_loss)\n",
    "\n",
    "            #print(image_ry.detach().shape[0],image_ry.detach().shape[1],image_ry.detach().shape[2])\n",
    "            #print((g_x(image_ry.detach())).shape[0],(g_x(image_ry.detach())).shape[1],(g_x(image_ry.detach())).shape[2])\n",
    "            #print(g_y(g_x(image_ry.detach())).shape[0],g_y(g_x(image_ry.detach())).shape[1],g_y(g_x(image_ry.detach())).shape[2])\n",
    "            \n",
    "        if(epoch == 1):\n",
    "            print('save model epoch %d'%epoch)\n",
    "            torch.save(g_x.state_dict(),model_path+'gy2x%d.pth'%epoch)\n",
    "            torch.save(d_x.state_dict(),model_path+'dx%d.pth'%epoch)\n",
    "            torch.save(g_y.state_dict(),model_path+'gx2y%d.pth'%epoch)\n",
    "            torch.save(d_y.state_dict(),model_path+'dy%d.pth'%epoch)\n",
    "        if (epoch%5 == 0):\n",
    "            print('save model epoch %d'%epoch)\n",
    "            torch.save(g_x.state_dict(),model_path+'gy2x%d.pth'%epoch)\n",
    "            torch.save(d_x.state_dict(),model_path+'dx%d.pth'%epoch)\n",
    "            torch.save(g_y.state_dict(),model_path+'gx2y%d.pth'%epoch)\n",
    "            torch.save(d_y.state_dict(),model_path+'dy%d.pth'%epoch)\n",
    "            \n",
    "            \n",
    "trian()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.utils import save_image\n",
    "from torch.autograd import Variable\n",
    "from models import GeneratorResNet\n",
    "from models import Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(max_step = 10,use_gpu = True,load_model = True,model_path = './model/'):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #g_a = GeneratorResNet((3,256,256),9)\n",
    "    g_a = Generator()\n",
    "    g_b = Generator()\n",
    "    cfg  = CFG()\n",
    "    g_a.load_state_dict(torch.load('./model/gx2y_5.pth'))\n",
    "    img  = Image.open(os.path.join('./data/my308470/trainA/female_10.jpg')).convert('RGB')\n",
    "    \n",
    "    g_b.load_state_dict(torch.load('./model/gy2x_5.pth'))\n",
    "    img2  = Image.open(os.path.join('./data/my308470/testB/0001.jpg')).convert('RGB')\n",
    "    #i2 = Variable(img)\n",
    "    t  = transforms.Compose(transforms_1) \n",
    "    i = t(img)\n",
    "    i = i.resize(1,3,256,256)\n",
    "\n",
    "    t  = transforms.Compose(transforms_1) \n",
    "    i2 = t(img2)\n",
    "    i2 = i2.resize(1,3,256,256)\n",
    "    #img = img.resize((256,256),Image.BICUBIC)    \n",
    "    #img = np.array(img)\n",
    "    #print(img)\n",
    "    #plt.imshow(i)\n",
    "    #img = torch.tensor(img)\n",
    "    #img = img.reshape(1,3,256,256).float()\n",
    "    #print(img.shape)\n",
    "    img_2 =  0.5*(g_a(i).data + 1.0)\n",
    "    save_image(img_2,'./data/output1.jpg')\n",
    "    img_3 =  0.5*(g_b(i2).data + 1.0)\n",
    "    save_image(img_3,'./data/output2.jpg')\n",
    "    return\n",
    "infer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torchcuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a698c97178a46cfbbc76da0074def26cfd86aacc76f0663171290501cf8bc714"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
